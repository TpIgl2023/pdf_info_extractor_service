Boosting Metaheuristics with Hybridized Low-Level Machine Learning for Enhanced Performance in Flow Shop Permutation Problems 
Chenni Nidhal Eddine1 , Bendaho Sarra1 , Nair Marwa1 , Berriche Aymene 1 , 
Yamani Mohammed Kamel1 , Adjal Mehdi Zakaria1 , Bessedik Malika2 
Abstract— The Permutation Flow Shop Scheduling Problem (PFSP) is a well-known combinatorial optimization problem that has been extensively studied in the literature. Traditional approaches, such as metaheuristics, have been widely used to tackle this problem, but often face limitations related to parameter selection, computational time, and the generation of initial solutions. To address these challenges, this paper proposes the utilization of two machine learning models based on the CatBoost regressor algorithm, tailored to the number of machines involved in the scheduling problem. By combining these two models with the Ant Colony Optimization (ACO) metaheuristic, we enhance its performance significantly. The first model focuses on generating high-quality initial solutions that outperform the commonly used NEH heuristic, all while maintaining computational efficiency. On the other hand, the second model is designed to expedite the enhancement of a given schedule through an efficient local search approach. To assess the efficacy of our proposed approach, we conducted extensive experiments, comparing its performance against traditional techniques using Taillard instances as benchmarks. The results of our evaluation consistently showcased the superiority of our approach, surpassing the performance of the benchmarked methods. 
keywords: Combinatorial optimization, Permutation Flow Shop Scheduling Problem , Machine learning, Makespan 
I. INTRODUCTION 
Optimization is a fundamental concept in various fields, including operations research, economics, and computer science. Essentially, optimization involves finding the best possible solution from a set of alternatives, taking into account specific objectives, constraints, and variables. It aims to maximize desired outcomes or minimize undesired results, thereby improving efficiency, effectiveness, and resource utilization. 
The permutation flow shop problem (PFSP) is a well-known NP-hard optimization challenge [1] that arises in different domains such as manufacturing, scheduling, and logistics. It involves determining an optimal sequence of tasks on a set of machines, considering the constraints of each machine, and minimizing a specific objective function. Efficiently solving this problem is crucial for enhancing productivity, reducing costs, and improving operational per-formance. 
Finding an optimal solution for PFSP is exponentially difficult as the problem size increases. Therefore, exact approaches are often impractical and limited to specialized algorithms such as branch and bound or dynamic program-ming. These methods can only handle small-sized problems effectively. since they aim to find the optimal solution by exhaustively exploring all possible permutations of tasks and evaluating their associated objective function values. In contrast, for larger scheduling problems, alternative solution approaches are commonly employed, such as heuristics, meta-heuristics (e.g., Tabu search, swarm optimization, or genetic algorithms), and artificial intelligence techniques like constraint programming and neural networks. The use of these methods allows for approximate solutions that are computationally more feasible and provide reasonably good results. 
Metaheuristics have been widely employed in the Per-mutation Flow Shop Scheduling Problem (PFSP) and have demonstrated impressive performance. However, these ap-proaches have certain limitations, primarily associated with parameter selection, computational time, and the generation of initial solutions, particularly in population-based meth-ods. To address these challenges, our objective is to lever-age machine learning techniques to mitigate these issues, specifically focusing on improving the generation of initial solutions and reducing the time required for local search in metaheuristics. To accomplish this, we have trained two machine learning models based on the CatBoost model, which comprises a collection of decision tree estimators tailored to the number of machines in the problem. The first model is designed to generate high-quality initial solutions that surpass the performance of the NEH heuristic while maintaining a comparable level of speed. The second model aims to enhance a given schedule promptly, allowing for instantaneous improvements in the solution quality. 
Our machine learning models were extensively evaluated on Taillard instances by comparing their performance to the most commonly used techniques in the literature for each specific task. For the first model, we specifically compared its performance against the widely recognized NEH heuristic. Similarly, for the second model, we conducted a bench-marking analysis against popular local search metaheuristics such as iterated local search (ILS) and Tabu Search (TS). The outcome of these comparisons was highly promising, as our machine learning models consistently outperformed the traditional techniques. This impressive performance im-provement further solidifies the effectiveness of employing machine learning in addressing the challenges associated with initial solution generation and enhancing the efficiency of local search algorithms within the PFSP domain. 
The two proposed models have been integrated into the Ant Colony Optimization (ACO), a population-based metaheuristic. This integration involves using the generative model to produce initial solutions, which are then used to initialize the pheromone intensities instead of starting from random intensities. Additionally, the improvement model is employed to apply local search techniques in order to refine the intermediate solutions. 
In order to thoroughly evaluate the effectiveness of our approach, we conducted comparison experiments with state-of-the-art techniques that are commonly employed for solv-ing the Permutation Flow Shop Problem (PSFP). These experiments allowed us to assess the performance of our hybrid ACO metaheuristic against existing approaches. 
The remaining sections of the paper are structured as fol-lows. The following section offers a concise literature review of the various methodologies utilized to tackle the Permuta-tion Flow Shop Scheduling Problem (PFSP). It emphasizes the application of metaheuristics, discusses their limitations, and explores the incorporation of machine learning tech-niques to augment their performance. This is followed by the "Problem Description" section, where we outline the spec-ifications and the formal description of the problem. Sub-sequently, we discuss our methodology, including Dataset Generation, which details the process used to create the dataset for training. We also present the construction of our machine learning models, outlining the steps involved and evaluating their performance. Afterwards, we transition to the "Results and Comparisons" section, where we thoroughly analyze the performance of our integrated models within the Ant Colony Optimization (ACO) metaheuristic and compare it against alternative techniques. Finally, we conclude the paper with a comprehensive summary of our findings and contributions. 
II. LITERATURE REVIEW 
In the quest for effective solutions to the flowshop schedul-ing problem, researchers have explored different approaches that can be broadly categorized into : exact approaches and approximate approaches including heuristics and metaheuris-tics. 
One commonly used exact approach for solving the flow-shop scheduling problem is based on dynamic programming [10]. This method constructs a table to store the optimal solu-tions for subproblems. By systematically filling the table and considering all possible permutations, the optimal sequence of tasks can be determined. 
Another exact approach frequently employed for flowshop permutation problems is B&B which was firstly introduced for scheduling problems by IIgnall and Schrage (1965) and Lomnicki (1965), addressing the makespan minimization in a three-machine PFSP and using proper criteria for branching and pruning nodes. Since then, studies improved this method exploring more efficient techniques of branching and pruning [11]. 
A wide range of heuristics have been developed to solve the PFSP. These heuristics have been extensively discussed in the literature and many studies have compared their effectiveness with regard to computational performance. One of the earliest and most well-known approaches for PFSP, is the Johnson’s rule proposed by Johnson in 1954 [22], it focuses on the assignment of tasks to only two machines. The algorithm identifies the task with the shortest processing time and assigns it to the machine with the least remaining processing time. This process is repeated until all jobs have been allocated. Palmer [25] has proposed a method which is an extension of the SPT (Shortest Processing Time) rule, in which tasks are ranked in ascending order of their tendency to have longer operating times. Campbell, Dudek and Smith [24] also introduced a method based on Johnson’s rule. It builds m−1 schedules by clustering the m original machines into two virtual machines and solving the generated two machine problem by repeatedly using Johnson’s rule. Gupta, using Johnson’s rule, introduces a new slope index [26], and the final sequence is obtained by sorting the jobs in ascending order of this index. Nawaz, Enscore and Ham [23]proposed a heuristic called "NEH" which consists of finding the scheduling of jobs according to the decreasing order of their total operating times and it builds the final sequence in a constructive way, adding a new job at each step and finding the best partial solution. 
Based on a recent survey [17], metaheuristics (MH) can be categorized into two distinct types based on their approach: single-solution-based MH and population-based MH. 
Metaheuristics that operate on a single solution basis can leverage local search techniques with or without memory. Examples of memory-less local search methods include Iterated Local Search (ILS) [12], Variable Neighborhood Descent (VND), Generalized Variable Neighborhood Search (GVNS) [9], and Greedy Randomized Adaptive Search Pro-cedures (GRASP) [27]. On the other hand, metaheuristics with memory incorporate techniques such as Tabu Search (TS), while those inspired by natural phenomena include Simulated Annealing (SA). These metaheuristics offer a robust and effective approach for exploring and refining solu-tions within the search space, making them particularly well-suited for addressing complex optimization problems like PFSP. What makes these metaheuristics appealing is their iterative improvement mechanism, where they continually search the neighborhood of the current solution and move towards better-quality solutions. This iterative process begins with an initial solution and applies local search operators repeatedly, exploring neighboring solutions with the aim of finding an optimal or near-optimal solution within a reasonable computational time. 
Alternatively, population-based metaheuristics (MH) em-ploy a collection of solutions to explore the search space. Several widely recognized population-based MH algorithms have proven to be highly effective when applied to the Permutation Flow Shop Problem (PFSP). Genetic Algorithms (GA), inspired by biology, start with an initial population of potential solutions and gradually improve them using genetic operations such as selection, crossover and mutation. By evaluating and favouring the most suitable individuals, genetic algorithms make it possible to find high-quality solu-tions to difficult optimisation problems. Another bio-inspired technique is Particle Swarm Optimization (PSO)[16], which is based onself-organising principles that enable a group of living organisms to act together in a complex way, based on simple simple rules. Tasgetiran et al. introduced an enhancement to the search process by incorporating a local search based on Variable Neighborhood Search (VNS) technique aiming to improve the quality of intermediate individuals during the search, leading to refined solutions. Ant Colony Optimization (ACO) [15] is a population-based cooperative search metaphor inspired by the foraging be-haviour of real ants. One of the ideas behind ACO is to use the equivalent of the pheromone path used by real ants as a means of cooperation and communication within an artificial ant colony. Another efficient metaheuristic that has garnered significant interest in the field of optimization is JAYA algorithm [18], it has been first applied to the PFSP in [13], its key characteristic involves simultaneously moving closer to the best solution and moving away from the worst solution of the given population, increasing its sensitivity to the quality of initial solutions. 
Numerous literature review studies have been conducted [17], exploring the amalgamation of Machine Learning (ML) techniques and Metaheuristics (MH) for specific or diverse purposes. A taxonomy of hybridizations between Machine Learning (ML) and Metaheuristics (MH) can be established based on the use of the ML in the MH : 
• Problem-level : where ML models can be used to approximate objective function, handle constraints, or to break large space problems into smaller ones. In the work presented by [28], an example of data space de-composition for a dynamic job shop scheduling problem was demonstrated. The approach involved clustering jobs based on their processing times. • Low-level : ML can be used to find good parameters of the MH including : initialisation, evolution and parameter setting. In this context, Radha Ramanan et al. [19] used an ANN with an improvement heuristic for the initialization of the population of a GA for the PFSP. A recent paper [21] introduced a deep reinforcement learning approach for the flexible flowshop scheduling problem using proximal policy opotimization (PPO). • High-level : where ML is mainly used for MH selection or generation. 
III. PROBLEM DESCRIPTION 
The flow-shop scheduling problem is defined by a set of m machines (M1, M2, M3...Mm) and n unrelated tasks (J1, J2, J3...Jn), considering that the number of machines and tasks is finite. Each task consists of a specific set of pro-cesses for an equal number of machines, with each process having a processing time Pij (where Pij represents the pro-cessing time of task i on machine j). The processes for each task must be executed in the same given order of machines, meaning that for all tasks, the processes are performed on machine 1, then on machine 2, until the last process is reached on machine m. The objective is to find an efficient sequence of tasks on the given machines that completes all processes in the minimal completion time known as the makespan criterion, while adhering to certain constraints[3]. This problem is deterministic since the processing times are known in advance. The notation for the classic flow-shop scheduling problem with the makespan criterion (Cmax) was initially introduced by Conway et al. [4]. They used notations such as n/m/F/Cmax or F//Cmax, which are equivalent to F/prmu/Cmax in the case of permutations. 
A sequence is represented by a job permutation π = {π1, π2, . . . , πn} , n jobs (j = 1, 2, . . . , n) will be sequenced through all m machines (k = 1, 2, . . . , m) using the same permutation. C (πj , m) denotes the completion time of job πj on machine m. The calculation of completion time for n-job m-machine problem is given as follows: 
C (π1, 1) = Pπ1,1 
C (πj , 1) = C (πj−1, 1) + Pπj ,1 
C (π1, k) = C (π1, k − 1) + Pπ1 ,k 
C (π j , k) = max {C (π j−1, k) , C (π j, k − 1)} + Pπj ,k 
with j = 2, .., n and k = 2, .., m 
Searching for the optimal sequence leads to identifying a permutation π∗ in the set of all permutations Π such that 
Cmax (π ∗) ≤ C (πn, m) ∀π ∈ Π 
There are several assumptions that are made regarding this problem [2]: 
• Each job can only be processed on a single machine simultaneously. • Each machine can handle one job at a time. • Preemption is not allowed i.e. jobs cannot be interrupted once processing begins. • The setup times of the jobs on machines are included in the processing times. • Machines are available continuously, without any down-time. • In-process inventory is allowed. If the next machine on the sequence needed by a job is not available, the job can wait and join the queue at that machine. 
In the present study, we examine a flow shop setup that encompasses five machines and has the flexibility to accom-modate various number of jobs. 
IV. METHODOLOGY 
A. Catboost Estimator 
CatBoost [5] is a gradient boosting framework that has gained significant attention for its effective use in regression tasks. One notable advantage of CatBoost is its ability to handle categorical features seamlessly. Additionally, it incorporates advanced regularization techniques that address the challenge of overfitting [6], a common issue in re-gression modeling. By integrating techniques like ordered target statistics and gradient-based adjustments, CatBoost effectively prevents the model from memorizing the training data and enables better generalization to unseen data. This regularization capability enhances the reliability and accu-racy of the regression predictions. 
CatBoost’s performance as a regression model has been validated in various benchmarks and competitions [7]. Its ability to handle categorical features, advanced regulariza-tion techniques, and support for missing values make it a powerful tool for researchers and practitioners in the field of regression modeling. With its robust capabilities, CatBoost serves as a valuable asset in tackling complex regression problems and delivering accurate predictions in diverse domains. 
Considering the numerous advantageous features dis-cussed, we have made the decision to employ CatBoost as the foundation for our two regression models. 
B. Generative model 
1) Data generation: We generate problem instances con-sisting of seven and ten jobs using the Taillard benchmarks of 20 or 50 jobs. These problem instances are solved using the Branch & Bound algorithm, which involves complete enumeration to find the optimal solutions. The input for our model will be derived from these solved instances. A total of 10,000 exemplars are generated through this process. Specifically, each seven-job problem yields seven input-output pairs known as exemplars, while each ten-job problem produces ten exemplars as will be detailed next. 2) Model architecture: The proposed model is a CatBoost regressor that takes as input a vector of size 3m, where m represents the number of machines. This design requires separate and individually trained models for flowshops with different numbers of machines. The input values need to be normalized since they must fall between zero and one. In this study, the minimum and maximum processing times in the flowshops range from 1 to 99 minutes. To ensure proper normalization, an equation is used with a divisor of 100. 
Each job is represented by a vector with elements that describe its processing time, relative to machine workloads, and other jobs in the schedule. The input for the model consists of 3m values distributed as follows: 
• The first m values represent the job’s processing times on each machine. • The middle m nodes represent the average processing times on each machine. • The last m nodes represent the standard deviation of processing times on each machine. 
The model is trained to capture the relationships between jobs within a given batch. The use of average processing times and standard deviations ensures clear differentiation between the same jobs in different batches, facilitating the training process. For example, Job 1 in batch 1,2,3,4,5 will be distinct from Job 1 in batch 1,2,3,4,6. The first m values in the vector representing Job 1 will always be the same, while the subsequent ten values will vary based on the batch of jobs it belongs to. 
The output consists of a single value, regardless of the number of machines (m). The output node produces values ranging from 0.1 to 0.9. When a job is presented to the model, the values assigned to the input vector are calculated using the following equations: 
job q=   pi,q 100 q = 1, . . . ,m ¯p(q−m) 100 q = m + 1, . . . , 2m X(q−2m)−n¯p2 (q−2m) (n−1)×104 q = 2m + 1, . . . , 3m 
where 
¯p(k) = 1 n  n i=1 pi,k where k = q − m 
and 
X(l) =  n i=1 p2 i,k where l = q − 2m 
for example taking the processing times in the next table: 
M1 
M2 
M3 
M4 
M5 
J1 
24 
32 
54 
14 
16 
J2 
15 
44 
18 
10 
32 
J3 
45 
23 
14 
8 
41 
J4 
12 
4 
25 
36 
4 
J5 
15 
16 
18 
22 
18 
Table 1: Example of a processing times matrix representing the processing times of 5 jobs on 5 machines. 
the input vector for J1 will be the concatenation of three m sized vector as mentioned in the next figure 
Fig. 1. The input encoding for job 1 
The generated vector will be processed by the CatBoost model, which will produce a value between 0.1 and 0.9. This process is repeated for each job in the schedule, resulting in a complete vector of n values . The job corresponding to the smallest value in that vector will be assigned as the first job, the job with the next smallest value will be the second job, and so on. This sequencing method is illustrated in the accompanying figure. 
Fig. 2. The decoding process for the outputs into a sequence of jobs. 
3) 
Performance evaluation: 
To assess the generative model’s performance before integrating it into a metaheuris-tic, we conduct a comparison with the NEH heuristic. This evaluation is carried out on the fourth benchmark of Taillard, which comprises 50 jobs and five machines. The comparison results, including the deviation and time obtained, are pre
-
sented in the following figures: 
Fig. 3. The Deviation from Taillard’s Upper Bounds in the Results 
Fig. 4. Execution Time of the Methods 
Upon analysis, it is evident that the generative model pro-duces highly comparable results to the NEH heuristic, with the model even surpassing the heuristic in 5 instances. Notably, a significant difference is observed in terms of execution time between the two approaches. 
C. Improvement model 
1) Data generation: Following the approach used in the previous model, we created problem instances comprising seven and ten jobs using the Taillard benchmarks that con-sisted of 20 or 50 jobs. Subsequently, we selected random job schedules and applied the best-known improvement meta-heuristics, GVNS (General Variable Neighborhood Search) [9] and Tabu Search, to enhance these schedules. The input for our model is derived from these improved instances. Through this process, a total of 20,000 exemplars are generated. Specifically, each seven-job problem generates seven input-output pairs known as exemplars, while each ten-job problem produces ten exemplars. The details of these exemplars will be further elaborated in the subsequent discussion. 2) Model architecture: In this model, the objective is to predict an improved schedule based on a given schedule and its corresponding processing times. The input vector for the model includes the same information as before. However, in order to incorporate local information about each job, we consider a window of two jobs. This means that, in addition to the original information, we include the processing times of the two previous jobs and the two next jobs of the current job in the input vector. Furthermore, we add a value that represents the current position of the job in the schedule to be improved. Consequently, the input vector will have a size of 3m + 4m + 1 , where 3m represents the original information about processing times of the current job, the mean and the std of processing times in each machine, 4m represents the additional information about the surrounding jobs, and 1 represents the current position value. This expanded input vector allows the model to consider more contextual details when predicting an improved schedule. In cases where a job does not have previous jobs, we use a padding of 0 in the input vector to represent the missing processing times. Similarly, if a job does not have next jobs, we use a padding of 1 in the input vector. These padding values are chosen to represent the minimum and maximum processing times in the dataset, respectively. By using these padding values, we ensure that all jobs in the input vector have the same size, regardless of their position in the schedule. To illustrate the generation of an input vector, consider the example shown in the accompanying figure. In this scenario, we take Job 1 as the current job. The window of jobs surrounding Job 1 includes the processing times of the two previous jobs, which are 5 and 4, and the processing times of the two next jobs, which are 2 and 3. Additionally, we include the position of the current job, which in this case is 3 out of 5. By incorporating this information into the input vector, we capture the contextual details necessary for the model to make predictions and improve the schedule effectively. 
Fig. 5. The input encoding for job1 
The model operates by receiving an input vector associated with one job at a time and predicting a value ranging from 0.1 to 0.9 for each job. When considering all the jobs, a vector of n values is obtained. This vector of values is then transformed into a new improved schedule, where the job corresponding to the smallest predicted value becomes the first job in the improved schedule, the job with the second smallest value becomes the second job, and so on exactly as we did in the generative model (Fig.2). In essence, the predicted values guide the ordering of the jobs, resulting in a more optimized and improved schedule. 
3) 
Performance evaluation: 
In order to assess the in
-
dependent performance of our model as an improvement method, we conducted a comparison with three well-known improvement metaheuristics: GVNS (General Vari
-
able Neighborhood Search), ILS (Iterated Local Search) [12], and Tabu Search. The evaluation was conducted on the benchmark4 dataset of Taillard, which consists of 50 jobs and 5 machines. 
We present the results of this comparison in the following two graphs. It should be noted that to ensure reasonable computation times, we used a small number of iterations for all the metaheuristics. We observed highly comparable results in terms of deviation when comparing our model to ILS and Tabu Search. In fact, our model even outperformed them in certain instances. However, the most notable aspect was the remarkable time efficiency of our method. The time taken by our model was significantly lower compared to the traditional improvement metaheuristics. This aspect highlights the impressive performance of our model in terms of both solution quality and computational efficiency. 
Fig. 6. The Deviation from Taillard’s Upper Bounds in the Results 
Fig. 7. Execution Time of the Methods 
V. RESULTS AND DISCUSSION 
The generative and improvement models can be combined with various metaheuristics to create hybrid approaches. However, for our experiment, we specifically utilized the ant colony system as the chosen metaheuristic. In this section, we will provide a concise overview of the ant colony metaheuristic and explain the process of integrating our two previous models with it. Subsequently, we will conduct empirical studies and comparisons, including a comparison with the non-hybridized ant colony system, as well as other metaheuristics such as GA, Jaya [13], and PSO [14]. 
Taking into consideration that the tests were conducted on a computer equipped with the Windows 11 operating system, an 11th generation i7 processor, and 32GB of RAM. 
1) Ant Colony system : Here, we have implemented the ant colony system method proposed by Ying et al.[15], where they consider the application of the MAX-MIN Ant System (MMAS) to the PFSP. The performance of ACO approaches in terms of solution quality and convergence speed can be further enhanced by incorporating a local search phase (Stützle and Hoos, 1997; Dorigo and Gambardella, 1997), in which ants are allowed to improve their solutions through a local search procedure. Thus, they applied the MAX-MIN Ant System to the FSP using a fast local search procedure to enhance the solutions constructed by the ants. The algorithm steps are detailed in the following pseudo-code. Algorithm 1 MAX-MIN ant system Initialize the pheromone trails 2: Initialize the number of ants Initialize the pheromone deposit and evaporation rate 4: while (stopping criteria not met) do 6: construct a solution for the ant Improve solution by local search 8: Update the pheromone trails ∀, τijτmax ≥ τij ≥ τmin end while 
10: 
Return best solution found 
Explanation of the steps in the pseudo-code: 
1)-Initialize the pheromone trails: The pheromone trails are represented in the form of a complete graph with a number of nodes corresponding to the tasks, and the amount of pheromone is represented by the weight of the edge. Initially, the pheromone matrix (weights) is initialized to 1. 2)-Construct a solution for the ant: The construction of a solution, as depicted in the following figure, begins by randomly selecting a job and then proceeds to other jobs in the matrix based on the pheromone intensity present on the current job’s edge as well as the edges of other jobs. The construction process terminates once a complete solution is obtained. Fig. 8. Construction of a Solution by an Ant 3)-Improve solution by local search: The previously constructed solution from the previous step will be improved through a local search procedure known as insertion local search, which is described in the follow-ing pseudo-code: Algorithm 2 Insertion local search for (each job in schedule) do 2: Try moving the job to every position in the sequence if (better schdule found) then 4: update the schedule end if 6: end for 4)- Update the pheromone trails: Finally, the pheromone intensities will be updated by adding a predefined amount of pheromones to the edges traversed by the solution generated through the local search. Additionally, all intensities will be reduced by a pre-defined evaporation rate. The update method is detailed as follows: 
Algorithm 3 Update pheromone trails 
for (each arc) do 
if 
(arc passed by the ant) 
then 
2: 
arc_weight*= (1-evaporation_rate) 
4: 
arc_weight+= pheromone_deposit 
end if 
6: 
arc
_
w 
← 
max(
pmin, 
min(
pmax, arc
_
w
)) 
end for 
2) 
Hybridizing the ant colony system with machine learn
-
ing: 
Our models can be effectively integrated with the ant colony system to enhance its performance. The generative model serves a crucial purpose by providing an initial solu
-
tion, which is utilized to initialize the pheromone intensity in the graph. This initialization step goes beyond simply setting the pheromone values to maximum or minimum values and instead leverages the generative model’s output to provide more informed guidance to the ants during their search. This improved initialization contributes to better exploration and exploitation of the solution space. Additionally, the improve
-
ment model takes over the traditional local search phase, allowing it to refine and enhance the solutions constructed by the ants. This integration of the improvement model further improves the overall solution quality and search efficiency of the ant colony system. 
• 
Empirical study
: Our main focus will be on determin
-
ing the optimal number of iterations and the number of ants needed to achieve satisfactory performance when hybridizing with our models. This is because the other parameters, such as pheromone deposit and evaporation rate, will continue to have a consistent impact on both ant systems. the results are shown in the next two figures, we used instance 5 of the first Taillard’s 
benchmark, It is observed that the hybrid ant system achieves excellent results with a significantly lower number of iterations and ants. 
Fig. 9. Deviation Variation of HAS with Iteration Changes 
Fig. 10. the obtained deviation of HAS with variation of ants number 
• 
AS and Hybrid AS
: We will examine the performance of both the hybrid Ant System (HAS) and the regular AS. To evaluate their performance, we conducted tests on the first benchmark of Taillard. The results, presented below, include the deviation (deviation from the optimal solution) and execution time. It is evident that the hybrid AS exhibits deviations that are very close to those of the regular AS, and in some instances, it even surpasses it. However, a substantial disparity is observed in terms of execution time, making the hybrid AS the preferred choice due to its faster speed without compromising the quality of solutions. 
Fig. 11. Deviation Variation between AS and HAS 
Fig. 12. Time Variation between AS and HAS 
3) 
Comparison to state-of-the-art metaheuristics: 
In order to provide a more comprehensive evaluation of the Hybrid Ant System (HAS), we conducted further comparisons with other state-of-the-art metaheuristics such as Genetic Algo
-
rithm (GA), Jaya, and Particle Swarm Optimization (PSO). The subsequent figures clearly illustrate that our approach exhibits competitive performance. Through a rigorous eval
-
uation, we compared the results obtained from our method with those achieved by the aforementioned metaheuristics. Despite the inherent complexity of the problem, our approach consistently attained comparable or even superior solutions in terms of both quality and efficiency. These results strongly indicate the effectiveness and competitiveness of our ap
-
proach when compared to the existing state-of-the-art meta-heuristic algorithms. 
Fig. 13. Deviation Variation between HAS and other metaheuristics 
Fig. 14. Time Variation between HAS and other metaheuristics 
VI. CONCLUSION 
This paper introduces two novel regression machine learn-ing models specifically designed for the flow shop permu-tation problem. These models serve two purposes: generat-ing initial solutions and improving existing solutions. The versatility of these models lies in their ability to seam-lessly integrate with any metaheuristic algorithm, making them highly valuable in the field of research. Through rigorous testing and evaluation, the proposed approach have demonstrated competitive results compared to state-of-the-art approaches. These findings highlight the potential of the models in enhancing the performance and effectiveness of existing methods in the field. 
REFERENCES 
[1] Reza Hejazi*, S., and S. Saghafian. "Flowshop-scheduling problems with makespan criterion: a review." International Journal of Production Research 43.14 (2005): 2895-2929. [2] Ramanan, T.R., Sridharan, R., Shashikant, K.S. and Haq, A.N., 2011. An artificial neural network based heuristic for flow shop scheduling problems. Journal of Intelligent Manufacturing, 22, pp.279-288. [3] Zaied, A.N.H., Ismail, M.M. and Mohamed, S.S., 2021. Permutation flow shop scheduling problem with makespan criterion: literature review. J. Theor. Appl. Inf. Technol, 99(4), pp.830-848. [4] Louis W. Miller Richard Walter Conway William L. Maxwell. Theory of Scheduling. 1967. [5] Dorogush, A.V., Ershov, V. and Gulin, A., 2018. CatBoost: gra-dient boosting with categorical features support. arXiv preprint arXiv:1810.11363. [6] Hancock, J.T. and Khoshgoftaar, T.M., 2020. CatBoost for big data: an interdisciplinary review. Journal of big data, 7(1), pp.1-45. [7] Al Daoud, E., 2019. Comparison between XGBoost, LightGBM and CatBoost using a home credit dataset. International Journal of Computer and Information Engineering, 13(1), pp.6-10. [8] Jabeur, S.B., Gharib, C., Mefteh-Wali, S. and Arfi, W.B., 2021. CatBoost model and artificial intelligence techniques for corporate failure prediction. Technological Forecasting and Social Change, 166, p.120658. [9] Tasgetiren, M.F., Buyukdagli, O., Pan, Q.K. and Suganthan, P.N., 2013. A general variable neighborhood search algorithm for the no-idle permutation flowshop scheduling problem. In Swarm, Evolutionary, and Memetic Computing: 4th International Conference, SEMCCO 2013, Chennai, India, December 19-21, 2013, Proceedings, Part I 4 (pp. 24-34). Springer International Publishing. [10] Michael S Salvador. « A solution to a special class of flow shop scheduling problems ». In : Symposium on the theory of scheduling and its applications. Springer. 1973, p. 83-91. [11] Caio Paziani Tomazella, Marcelo Seido Nagano. A comprehensive review of Branch-and-Bound algorithms: Guidelines and directions for further research on the flowshop scheduling problem. Expert Systems with Applications, 2020. [12] Dong, X., Huang, H. and Chen, P., 2009. An iterated local search algorithm for the permutation flowshop problem with total flowtime criterion. Computers and Operations Research, 36(5), pp.1664-1669. [13] Mishra, A. and Shrivastava, D., 2020. A discrete Jaya algorithm for permutation flow-shop scheduling problem. International Journal of Industrial Engineering Computations, 11(3), pp.415-428. [14] Tasgetiren, M.F., Sevkli, M., Liang, Y.C. and Gencyilmaz, G., 2004. Particle swarm optimization algorithm for permutation flowshop se-quencing problem. In Ant Colony Optimization and Swarm Intelli-gence: 4th International Workshop, ANTS 2004, Brussels, Belgium, September 5-8, 2004. Proceedings 4 (pp. 382-389). Springer Berlin Heidelberg. [15] Ying, K.C. and Liao, C.J., 2004. An ant colony system for permutation flow-shop sequencing. Computers and Operations Research, 31(5), pp.791-801. [16] Tasgetiren, M. Fatih, et al. "Particle swarm optimization algorithm for permutation flowshop sequencing problem." Ant Colony Optimization and Swarm Intelligence: 4th International Workshop, ANTS 2004, Brussels, Belgium, September 5-8, 2004. Proceedings 4. Springer Berlin Heidelberg, 2004. [17] El-Ghazali Talbi. “Machine learning into metaheuristics: A survey and taxonomy of data-driven metaheuristics”. In: Working paper (2020), pp. 1–30. [18] Rao. « Jaya : A simple and new optimization algorithm for solving constrained and unconstrained optimization problems ». In : Interna-tional Journal of Industrial Engineering Computations 7.1 (2016), p. 19-34. [19] Ramanan T, Radha & Sridharan, Rajagopalan and Kulkarni, Sarang and Haq, A.. (2011). An artificial neural network based heuristic for flow shop scheduling problems. Journal of Intelligent Manufacturing. 22. 279-288. 10.1007/s10845-009-0287-5. [20] Seyyedabbasi, A., Aliyev, R., Kiani, F., Gulle, M. U., Basyildiz, H., and Shah, M. A. (2021). Hybrid algorithms based on combining reinforcement learning and metaheuristic methods to solve global optimization problems. Knowledge-Based Systems, 223, 107044. [21] Zhu, J., Wang, H., Zhang, T. (2020). A Deep Reinforcement Learn-ing Approach to the Flexible Flowshop Scheduling Problem with Makespan Minimization. 2020 IEEE 9th Data Driven Control and Learning Systems Conference (DDCLS). [22] Johnson, S. (1954). Optimal two-and three-stage production schedules with setup times included. Naval Research Logistics Quarterly, 1(1), 61–68. [23] Nawaz, M., Enscore, J., & Ham, I. (1983). A Heuristic algorithm for the m-machine, n-job flow shop sequencing problem. OMEGA. International Journal of Management Science, 11(1), 91–95. [24] Campbell, H. R., & Smith, D. M. (1970). A heuristic algorithm for n-jobs m-machines sequencing problem. Management Science, 16, 630–637. [25] Palmer, D. (1965). Sequencing jobs through a multi-stage. Process in the minimum total time—a quick method of obtaining a near optimum. Operations Research, 16, 45–61. [26] Gupta, J. (1971). A functional heuristic algorithm for the flow shop scheduling problem. Operational Research Quarterly, 22, 27–39. [27] Hugo Barbalho et al. « A hybrid data mining GRASP with path-relinking ». In : Computers & Operations Research 40.12 (2013), p. 3159-3173. [28] M. Adibi and J. Shahrabi. 2014. A clustering-based modified variable neighborhood search algorithm for a dynamic job shop scheduling problem. The International Journal of Advanced Manufacturing Tech-nology 70 (02 2014). 
